{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzione a Keras\n",
    "\n",
    "Keras viene utilizzato come front end di TensorFlow, importato come modulo usando `from tensorflow import keras` ovvero direttamente dalla distribuzione Keras usando `import keras`. Nel secondo caso keras sarà stato già installato usando `pip`o `conda`.\n",
    "\n",
    "L'API di Keras ha due forme distinte: la API `Sequential` che costruisce il modello aggiungendo oggetti della classe `Layers` e la API funzionale che usa la classe `Model` per costruire il modello in modo tale che ogni layer sia l'input di una funzione che calcola il successivo.\n",
    "\n",
    "Classifichiamo le cofre MNIST conuna semplice rete convoluzionale con API `Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "\n",
    "# parametri del modello\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Carichiamo il data set\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scaliamo le immagini nel range [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Impostiamo la shape dei tensori a (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# Convertiamo i vettori delle classi in matrici binarie\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creiamo il modello\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 4s 74us/sample - loss: 0.3819 - acc: 0.8840 - val_loss: 0.0826 - val_acc: 0.9780\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.1083 - acc: 0.9674 - val_loss: 0.0523 - val_acc: 0.9862\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0810 - acc: 0.9750 - val_loss: 0.0475 - val_acc: 0.9877\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0683 - acc: 0.9788 - val_loss: 0.0412 - val_acc: 0.9888\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0383 - val_acc: 0.9897\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0529 - acc: 0.9836 - val_loss: 0.0360 - val_acc: 0.9898\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0490 - acc: 0.9846 - val_loss: 0.0384 - val_acc: 0.9902\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 2s 40us/sample - loss: 0.0475 - acc: 0.9851 - val_loss: 0.0345 - val_acc: 0.9917\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0420 - acc: 0.9865 - val_loss: 0.0302 - val_acc: 0.9915\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0406 - acc: 0.9878 - val_loss: 0.0314 - val_acc: 0.9917\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0369 - acc: 0.9882 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0360 - acc: 0.9884 - val_loss: 0.0311 - val_acc: 0.9920\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0345 - acc: 0.9891 - val_loss: 0.0299 - val_acc: 0.9908\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0316 - acc: 0.9892 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0312 - acc: 0.9898 - val_loss: 0.0291 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc818385a10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impostiamo i parametri di addestramento\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "# Compiliamo il modello inserendo la loss, l'ottimizzatore e la metrica\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Addestramento\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.023806728808558546\n",
      "Test accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/rpirrone/.keras/datasets/COVID-19_Chest_CT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22945/175013011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creiamo la directory dei dati e spostiamoci in essa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/rpirrone/.keras/datasets/COVID-19_Chest_CT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/rpirrone/.keras/datasets/COVID-19_Chest_CT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Download url delle TAC normali\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/rpirrone/.keras/datasets/COVID-19_Chest_CT'"
     ]
    }
   ],
   "source": [
    "# Creiamo la directory dei dati e spostiamoci in essa\n",
    "os.makedirs(\"/home/rpirrone/.keras/datasets/COVID-19_Chest_CT\")\n",
    "os.chdir(\"/home/rpirrone/.keras/datasets/COVID-19_Chest_CT\")\n",
    "\n",
    "# Download url delle TAC normali\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Download url delle TAC anormali\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Creiamo la directory per conservare i dati\n",
    "os.makedirs(\"MosMedData\")\n",
    "\n",
    "# Unzip degli archivi\n",
    "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")\n",
    "\n",
    "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dati sono in formato Nifti che è un formato tipico dei volui TAC e si basa sul formato DICOM\n",
    "# Eseguiremo il seguente preprocessing\n",
    "# - Rotazione di 90 gradi per allinearli\n",
    "# - Scaling dei valori nativi di intensità (Hounsfield Unit - HU - compresi tra -1024 e 2000) in [0-1]\n",
    "# - Resize delle tre dimensioni del volume\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "os.chdir(\"/home/rpirrone/.keras/datasets/COVID-19_Chest_CT\")\n",
    "\n",
    "# Dimensioni desiderate\n",
    "desired_depth = 64\n",
    "desired_width = 128\n",
    "desired_height = 128\n",
    "\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Legge e carica il volume\"\"\"\n",
    "    # Legge il file\n",
    "    scan = nib.load(filepath)\n",
    "\n",
    "    # Carica i dati grezzi\n",
    "    scan = scan.get_fdata()\n",
    "\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalizza il volume\"\"\"\n",
    "    # I valori delle TAC sono in Hounsfield Units (HU) che hanno escursione in\n",
    "    # un intervallo ampio: normalizziamo in [0, 1]\n",
    "    volume = volume.astype(\"float32\")\n",
    "\n",
    "    min = np.min(volume)\n",
    "    max = np.max(volume)\n",
    "\n",
    "    volume = (volume - min) / (max - min)\n",
    "\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(volume, w, h, d):\n",
    "    \"\"\"Ridimensiona lungo l'asse z\"\"\"\n",
    "\n",
    "    # Calcolo dei fattori di scala\n",
    "    depth_factor = d / volume.shape[-1]\n",
    "    width_factor = w / volume.shape[0]\n",
    "    height_factor = h / volume.shape[1]\n",
    "\n",
    "    # Rotazione di 90 gradi\n",
    "    volume = ndimage.rotate(volume, 90, reshape=False)\n",
    "\n",
    "    # Ridimensionamento lungo l'asse z\n",
    "    volume = ndimage.zoom(volume, (width_factor, height_factor, depth_factor), order=1)\n",
    " \n",
    "    return volume\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Lettura, normalizzazione e ridimensinamento del volume\"\"\"\n",
    "    # Lettura\n",
    "    volume = read_nifti_file(path)\n",
    "    # Nornalizzazione\n",
    "    volume = normalize(volume)\n",
    "    # Ridimensionamento\n",
    "    volume = resize_volume(volume, desired_width, desired_height, desired_depth)\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scansioni TAC con tessuti polmonari normali: 100\n",
      "Scansioni TAC con tessuti polmonari anormali: 100\n"
     ]
    }
   ],
   "source": [
    "# La cartella \"CT-0\" consiste di scansioni TAC che riportano tessuti polmonai normali\n",
    "# senza segni di polmonite virale\n",
    "normal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-0\")\n",
    "]\n",
    "# LA cartella \"CT-23\" consiste di scansioni TAC con molte opacità \"a vetro smerigliato\"\n",
    "# che coinvolgono il parenchima polmonare\n",
    "abnormal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-23\")\n",
    "]\n",
    "\n",
    "print(\"Scansioni TAC con tessuti polmonari normali: \" + str(len(normal_scan_paths)))\n",
    "print(\"Scansioni TAC con tessuti polmonari anormali: \" + str(len(abnormal_scan_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I campioni nel training e validation set sono 140 e 60.\n"
     ]
    }
   ],
   "source": [
    "# Costruzione del training set e del validation set\n",
    "\n",
    "# Lettura e processing delle scansioni\n",
    "# Ridimensionamento e scalatura\n",
    "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
    "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
    "\n",
    "# Le scansioni anormali sono in classe 1 mentre quelle normali in classe 0\n",
    "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
    "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
    "\n",
    "# Creiamo un rapporto 70% - 30% per il traning e il validaiton set\n",
    "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
    "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
    "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
    "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
    "print(\n",
    "    \"I campioni nel training e validation set sono %d e %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# I volumi saranno ruotati di alcuni gradi per generare nuovi campioni\n",
    "# Si aggiungerà un canale nella quarta dimensione per consentire il processing dei\n",
    "# minibatch sui dati che sono tridimensionali per cui la shape cambierà da\n",
    "# (sample, height, width, depth) a (sample, height, width, depth, 1)\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "@tf.function # decoratore per usare l'effettiva funzione di rotazione come parte dell'elaborazione TF\n",
    "def rotate(volume):\n",
    "    \"\"\"Ruota il volume di alcuni gradi\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # Angoli di rotazione prescelti\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # selezioniam gli angoli casualmente\n",
    "        angle = random.choice(angles)\n",
    "        # ruotiamo. il volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Aggiunge un canale e ruota il training set\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    #volume = tf.expand_dims(volume, axis=3)\n",
    "    volume = tf.reshape(volume,shape=(128, 128, 64, 1))\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Aggiunge solamente il canale al validation set\"\"\"\n",
    "    #volume = tf.expand_dims(volume, axis=3)\n",
    "    volume = tf.reshape(volume,shape=(128, 128, 64, 1))\n",
    "    return volume, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_24354/1326871102.py:24: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n",
      "(TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64), Dimension(1)]), TensorShape([Dimension(None)]))\n",
      "(TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64), Dimension(1)]), TensorShape([Dimension(None)]))\n"
     ]
    }
   ],
   "source": [
    "# Creiamo i data loader\n",
    "with tf.device('CPU:0'):\n",
    "    \n",
    "    train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "    batch_size = 2\n",
    "    # Data augmentation al volo durante l'addestramento\n",
    "    train_dataset = (\n",
    "        train_loader.shuffle(len(x_train))  # shuffling dei campioni\n",
    "        .map(train_preprocessing)           # preprocessing \n",
    "        .batch(batch_size)                  # impostazione del batch size\n",
    "        .prefetch(2)                        # due campioni sono sempre pre-caricati per il successivo \n",
    "                                            # passo di addestramento\n",
    "    )\n",
    "    # il validation preprocessing è solo scalatura\n",
    "    validation_dataset = (\n",
    "        validation_loader.shuffle(len(x_val))\n",
    "        .map(validation_preprocessing)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(2)\n",
    "    )\n",
    " \n",
    "print(tf.data.get_output_shapes(train_dataset))\n",
    "print(tf.data.get_output_shapes(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rpirrone/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 64, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 126, 126, 62, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 63, 63, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 63, 63, 31, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 6, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 12, 12, 4, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,352,897\n",
      "Trainable params: 1,351,873\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creiamo il modello\n",
    "\n",
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Costruisce un modello per una CNN 3D\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Definisce il modello\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Costruzione del modello\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rpirrone/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 70 steps, validate on 30 steps\n",
      "Epoch 1/100\n",
      "70/70 - 91s - loss: 0.7720 - acc: 0.4357 - val_loss: 0.6996 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "70/70 - 81s - loss: 0.7639 - acc: 0.5214 - val_loss: 0.6931 - val_acc: 0.4667\n",
      "Epoch 3/100\n",
      "70/70 - 81s - loss: 0.6860 - acc: 0.5857 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "70/70 - 80s - loss: 0.7639 - acc: 0.4857 - val_loss: 0.7276 - val_acc: 0.4833\n",
      "Epoch 5/100\n",
      "70/70 - 80s - loss: 0.6564 - acc: 0.6214 - val_loss: 0.7702 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "70/70 - 80s - loss: 0.7014 - acc: 0.6143 - val_loss: 0.7603 - val_acc: 0.5000\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24354/599753242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/virtualenvs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compila il modello\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Definisce le callback per il model checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Addestra facendo validazione ad ogni epoca\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
