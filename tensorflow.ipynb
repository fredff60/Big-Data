{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzione a Tensorflow\n",
    "\n",
    "TensorFlow (TF) è la API di Google per lo sviluppo di modelli di Deep Learning. Interagiremo con TF in Python, ma è possibile usare altri linguaggi, almeno a basso livello. La tipica applicazione TF lavora secondo lo schema riportato di seguito:\n",
    "\n",
    "<img src=\"https://pic1.zhimg.com/80/v2-8b46a7f55b77f0febfa3ad5084e25c3c_1440w.jpg\" alt=\"Architettura TF\" width=\"50%\" />\n",
    "\n",
    "- Keras è una nota libreria per specificare ad alto livello i layer del modello che lavora anche con altri back-end\n",
    "- La Data API è il modulo `tf.data` di TF che serve a specificare le azioni da compiere sul data set ai fini di addestramento e test\n",
    "- L'Execution Engine di TF (che può essere locale o anche distribuito su più nodi di un cluster di calcolo) rappresenta il nucleo vero e proprio di TF. A questo livello, vengono esposte API in diversi linguaggi.\n",
    "\n",
    "Nell'execution engine, viene definita la _sessione_ di lavoro `tf.Session(...)` in cui si svolgono le operazioni atomiche (`tf.Operation`) sui dati in forma tensoriale (`tf.Tensor`). \n",
    "\n",
    "La sessione gestisce l'esecuzione di un _*grafo di computaizone*_ ovvero di una specifica _astratta_ della sequenza di operazioni secondo una struttura a grafo dove i nodi sono operazioni che restituiscono tensori che vanno in ingresso ad altri nodi secondo la struttura definita dagli archi.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2994/1*vPb9E0Yd1QUAD0oFmAgaOw.png\" alt=\"Esempio grafo computazione\" width=\"50%\" />\n",
    "\n",
    "L'esecuzione si ottiene attraverso il metodo `tf.Operation.run()` che è ereditato anche dalla sessione ovvero si può valutare un singolo tensore con `tf.Tensor.eval()`. La sessione va chiusa esplicitamente con il metodo `close()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "b'Hello World'\n",
      "The session is closed? False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "\n",
    "# Sostituisce la vecchia chiamata tf.Session() \n",
    "# che è deprecata da quando è stato rilasciato TF v.2\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# chiediamo la lista dei device di calcolo presenti\n",
    "# quelli di tipo XLA_GPU o XLA_CPU sono abilitati all'algebra lineare accelerata\n",
    "for d in sess.list_devices():\n",
    "    print(d.name)\n",
    "\n",
    "# Definiamo una semplice computazione che definisce un elemento (o meglio un **nodo**)\n",
    "# costante di tipo stringa e lo esegue ottenendone la stampa\n",
    "bye_bye = tf.constant('Hello World')\n",
    "result = sess.run(bye_bye)\n",
    "\n",
    "print(result)\n",
    "\n",
    "print(f'The session is closed? {sess._closed}')\n",
    "# chiudiamo la sessione\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sessione può essere invocata con diverse opzioni e, soprattutto, con la possibilità di definire un _context manager_ all'interno del quale specificare le operazioni che non richiede più la chiusura esplicita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_2:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n",
      "6 <dtype: 'int32'> ()\n",
      "Session closed: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # definizione di due valori costanti interi\n",
    "    n1=tf.constant(2)\n",
    "    n2=tf.constant(3)\n",
    "    \n",
    "    print(n1.eval())\n",
    "    \n",
    "     #n3 = n1 * n2    # questa **non è** la moltiplicaione tra interi, \n",
    "                    # ma la tf.Operation di moltiplicazione tra tensori\n",
    "    \n",
    "    n3 = tf.multiply(n1,n2)\n",
    "        \n",
    "    print(n1,n2,n3,sep='\\n')\n",
    "    \n",
    "    #print(sess.run(n3))\n",
    "    print(n3.eval(), n3.dtype, n3.shape)\n",
    "\n",
    "print(f'Session closed: {sess._closed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintassi completa del costruttore dell'oggetto `tf.compat.v1.Session` è:\n",
    "\n",
    "```python\n",
    "tf.compat.v1.Session(target='',\\        # engine di computazione da utilizzare, locale o distribuito\n",
    "                    graph=None,\\        # grafo di computazione da utilizzare\n",
    "                    config=None)        # oggetto con le specifiche particolari di configurazione\n",
    "```\n",
    "\n",
    "Apriamo la sessione con una configurazione di default per l'allocazopne dinamica della computazione sui diversi device disponibili ed eseguiamo il grafo di computazione della figura precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv/Cast_1: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "1.875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Usiamo esplicitamente l'oggetto di configurazione\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
    "    allow_soft_placement=True,      # gestione dinamica dell'allocazione dei device\n",
    "    log_device_placement=True))     # registrazione del log sull'allocazione dei device\n",
    "\n",
    "with sess.as_default():\n",
    "    assert tf.compat.v1.get_default_session() is sess # impostiamo la nostra sessione configurata come quella di default\n",
    "    \n",
    "    # La nostra computazione è: res = (a*b) / (a+b)\n",
    "    \n",
    "    # ingressi\n",
    "    a = tf.constant(5)\n",
    "    b = tf.constant(3)\n",
    "    \n",
    "    # operazioni intermedie\n",
    "    prod = tf.multiply(a,b)\n",
    "    sum = tf.add(a,b)\n",
    "    \n",
    "    # uscita\n",
    "    #res = tf.div(prod,sum)\n",
    "    res = tf.math.divide(prod,sum)\n",
    "\n",
    "    \n",
    "    #print(res.eval())\n",
    "    print(sess.run(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Creiamo tensori con diverse funzioni\n",
    "mat = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "\n",
    "print(mat.shape, mat.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_normal:0\", shape=(3, 3), dtype=float32)\n",
      "Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv/Cast_1: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal: (Add): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform: (Add): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Const_2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "[[-2.0744095  -0.24003883  1.5144365 ]\n",
      " [-0.17038149 -2.5960207  -1.188079  ]\n",
      " [-1.5299348   0.34452125 -0.49177837]]\n",
      "[[0.14536846 0.6468046  0.6251013  0.9200802 ]\n",
      " [0.41084158 0.18548429 0.43867946 0.8946738 ]\n",
      " [0.87436116 0.7000619  0.46352565 0.166525  ]\n",
      " [0.06613743 0.57079065 0.7628063  0.34697175]]\n"
     ]
    }
   ],
   "source": [
    "mat_randn = tf.random.normal((3,3), mean=0, stddev=1.0)\t            # A 3ｘ3 random normal matrix.\n",
    "mat_randu = tf.random.uniform((4,4), minval=0, maxval=1.0)\n",
    "\n",
    "print(mat_randn)\n",
    "\n",
    "with sess.as_default():\n",
    "    assert tf.compat.v1.get_default_session() is sess\n",
    "    \n",
    "    \n",
    "    print(mat_randn.eval())\n",
    "    print(mat_randu.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[0.5368296  0.5577097  0.95285404 0.72499657]\n",
      " [0.92383134 0.3147235  0.07189012 0.5213605 ]\n",
      " [0.9221605  0.7092     0.36317253 0.6396687 ]\n",
      " [0.23651493 0.44773293 0.67429364 0.56049836]]\n"
     ]
    }
   ],
   "source": [
    "# Esempio di uso delle variabili\n",
    "with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "\n",
    "    init_values = tf.random.uniform((4,4), minval=0, maxval=1.0)\n",
    "\n",
    "    t = tf.Variable(initial_value=init_values,name='myvar')\n",
    "\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    \n",
    "    print(sess.run(init))\n",
    "    print(sess.run(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.  24.  48.]\n",
      " [ 88. 130. 180.]]\n"
     ]
    }
   ],
   "source": [
    "# Definiamo i placeholder per z = 2x^2 + 2xy\n",
    "with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "\n",
    "    two = tf.constant(2.0)\n",
    "    \n",
    "    x = tf.compat.v1.placeholder(tf.float32,shape=(None, 3))\n",
    "    \n",
    "    y = tf.compat.v1.placeholder(tf.float32,shape=(None, 3))\n",
    "    \n",
    "    z = tf.add(tf.multiply(two, tf.multiply(x, x)),\\\n",
    "                tf.multiply(two, tf.multiply(x, y)))\n",
    "    \n",
    "    print(sess.run(z, feed_dict={x: [[1., 2., 3.],[4., 5., 6.]], y: [[3., 4., 5.],[7., 8., 9.]]}))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8fa43838452e9e93f8e7562de70ac54321a3b66f4651442f84440771fb9be48"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
