{
 "cells": [
  {
   "source": [
    "# Uso di HDFS\n",
    "\n",
    "Hadoop Distributed File System (HDFS) è il File System distribuito di riferimento per le applicazioni di elaborazione Big Data del cosiddetto _Ecosistema Hadoop_.\n",
    "\n",
    "HDFS si accompagna a YARN (Yet Another Resource Negotiator) che fa da Resource Manager per la computazione distribuita sul cluster Hadoop. Un'applicazione Hadoop può essere sviluppata direttamente con le API Java ovvero attraverso uno dei molteplici framework che fanno a front-end per lo sviluppo e che mappano il proprio codice nativo in processi Java gestiti da YARN direttamente sul cluster.\n",
    "\n",
    "\n",
    "## Installazione\n",
    "\n",
    "Il prerequisito è l'installazine del Java JDK la cui cartella di installazione dovrà essere esposta esplicitamente come variabile di ambiente ```JAVA_HOME```.\n",
    "\n",
    "I processi Hadoop hanno la necessità di connettersi in ``ssh`` senza password al server del filesystem ovvero al nodemanager. Per configurare questa opzione su ``localhost``, al fine di realizzare una configurazione a singolo nodo, eseguire i seguenti comandi nella shell:\n",
    "\n",
    "```bash\n",
    "$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\n",
    "$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
    "$ chmod 0600 ~/.ssh/authorized_keys\n",
    "````\n",
    "\n",
    "A questo punto, si può scaricare il sorgente ```.tar.gz``` di Hadoop dalla sua [home page](https://hadoop.apache.org/releases.html) e procedere all'installazione vera e propria.\n",
    "\n",
    "_Nota per MacOS X:_ è possibile installare Hadoop con ```brew install hadoop```\n",
    "\n",
    "\n",
    "## Configurazione\n",
    "\n",
    "La configurazione del cluster consiste nella personalizzazione di alcuni file `xml` che stabiliscono il comportamento di HDFS e YARN e che si trovano nella cartella ```/percorso/di/installazione/etc/hadoop```. In questi file andranno riportate delle proprietà di configurazione organizzate come coppie nome-valore. Di seguito si riporta la configurazione distribuita con un solo nodo all'indirizzo ``localhost``.\n",
    "\n",
    "### ```core_site.xml```\n",
    "\n",
    "Definisce essenzialmente l'URL del server HDFS per la connessione dei processi interessati. La web interface per l'utente si trova all'indirizzo [http://localhost:9870](http://localhost:9870).\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://localhost:9099</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "### ```hdfs_site.xml```\n",
    "\n",
    "Definisce il numero dei nodi.\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>1</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "### ```yarn_site.xml```\n",
    "\n",
    "Definisce il tipo di servizio del nodemanager di YARN e le variabili di ambiente di cui questo ha bisogno (sono tutte gestite direttamente dall'installazione tranne ``JAVA_HOME``). La web interface per l'utente per monitorare i processi sul cluster si trova all'indirizzo [http://localhost:8088](http://localhost:8088).\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>yarn.nodemanager.aux-services</name>\n",
    "        <value>mapreduce_shuffle</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.nodemanager.env-whitelist</name>\n",
    "        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "### ```mapred_site.xml```\n",
    "\n",
    "Definisce YARN quale framework di esecuzione di Map Reduce e istanzia il ``classpath`` per le applicazioni.\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>mapreduce.framework.name</name>\n",
    "        <value>yarn</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>mapreduce.application.classpath</name>\n",
    "        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "### Avvio del cluster\n",
    "\n",
    "La prima volta che sia avvia il cluster, si deve formattare il datanode con il comando ``/percorso/di/installazione/bin/hdfs namenode -format``. Ad ogni avvio/stop del cluster e del resource manager si possono usare gli script appositi ``start-all.sh`` e ``stop-all.sh`` che si trovano in ``/percorso/di/installazione/sbin``\n",
    "\n",
    "\n",
    "## Uso della shell\n",
    "\n",
    "I comandi interattivi per la shell di HDFS si possono invocare come argomenti di ``hadoop fs`` ovvero di ``hdfs dfs``. La forma è la stessa:\n",
    "\n",
    "```bash\n",
    "$ hdfs dfs -<comando> [-<opzioni_comando>] <argomenti_comando>\n",
    "\n",
    "$ hadoop fs -<comando> [-<opzioni_comando>] <argomenti_comando>\n",
    "```\n",
    "\n",
    "In generale ``<comando>`` è uno dei tipici comandi di shell UNIX insieme con le sue opzioni. La documentazione completa si trova sul sito di [Apache Hadoop](https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}